{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5285ceb4-8dda-41ee-a873-52984de558ee",
   "metadata": {},
   "source": [
    "## Сверточные нейронные сети\n",
    "\n",
    "Идея создания сверточных нейронных сетей обсуждалась еще в середине XX века. Но к ней вернулись лишь в 2012 году. Тогда математики Алекс Крижевский и Джеффри Хинтон (Нобелевка по физике 2024) представили на международном конкурсе нейросеть AlexNet. По сравнению с аналогичными моделями она совершала почти на 50% меньше ошибок при распознавании изображений: их количество снизилось с 26 до 15%. Сейчас точность стала еще выше. Например, при распознавании лиц в толпе показатель составляет 99,8%\n",
    "\n",
    "![cnn](./lecture8/cnn.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26e8e564-08ff-4bf9-a94c-fc736a147c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "# Загрузка данных CIFAR-10\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffbb0d-ba40-4d19-8761-d6212aba39b6",
   "metadata": {},
   "source": [
    "### Размеченные данные - 10 категорий\n",
    "\n",
    "![table](./lecture8/labels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7102faf1-0ee9-48c2-b01b-680f4733184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 0\n",
    "plt.imshow(np.array(test_images[n,:,:,:]))\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()\n",
    "print(test_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2cac021-7b19-457a-b07a-1ab9c1de2f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 45ms/step - accuracy: 0.3433 - loss: 1.7700 - val_accuracy: 0.5264 - val_loss: 1.3115\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 39ms/step - accuracy: 0.5721 - loss: 1.1980 - val_accuracy: 0.5990 - val_loss: 1.1445\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.6366 - loss: 1.0307 - val_accuracy: 0.6175 - val_loss: 1.0745\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.6783 - loss: 0.9275 - val_accuracy: 0.6840 - val_loss: 0.9218\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 39ms/step - accuracy: 0.7032 - loss: 0.8463 - val_accuracy: 0.6701 - val_loss: 0.9490\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.7285 - loss: 0.7793 - val_accuracy: 0.6941 - val_loss: 0.8890\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.7438 - loss: 0.7322 - val_accuracy: 0.6890 - val_loss: 0.8958\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.7588 - loss: 0.6880 - val_accuracy: 0.6990 - val_loss: 0.8928\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 36ms/step - accuracy: 0.7757 - loss: 0.6434 - val_accuracy: 0.6981 - val_loss: 0.9012\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 34ms/step - accuracy: 0.7892 - loss: 0.5980 - val_accuracy: 0.7053 - val_loss: 0.8923\n",
      "313/313 - 5s - 14ms/step - accuracy: 0.7053 - loss: 0.8923\n",
      "Test accuracy: 0.7053\n"
     ]
    }
   ],
   "source": [
    "# Нормализация пикселей (0-255 -> 0-1)\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Создание модели CNN\n",
    "model = models.Sequential([\n",
    "    # Свёрточные слои + пулинг\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "\n",
    "    # Полносвязные слои\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)  # 10 классов для CIFAR-10\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Оценка\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3060a-e17c-4a8e-9790-082a92a00848",
   "metadata": {},
   "source": [
    "### **Формула вычисления Accuracy**  \n",
    "**Accuracy (точность)** — это одна из основных метрик для оценки качества классификационных моделей в машинном обучении. Она показывает долю правильно предсказанных объектов относительно общего количества предсказаний.  \n",
    "\n",
    "Accuracy вычисляется по формуле:  \n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Количество верных предсказаний}}{\\text{Общее количество предсказаний}} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$  \n",
    "\n",
    "Где:  \n",
    "- **TP (True Positives)** — количество верно предсказанных положительных примеров.  \n",
    "- **TN (True Negatives)** — количество верно предсказанных отрицательных примеров.  \n",
    "- **FP (False Positives)** — количество отрицательных примеров, ошибочно предсказанных как положительные.  \n",
    "- **FN (False Negatives)** — количество положительных примеров, ошибочно предсказанных как отрицательные.\n",
    "\n",
    "\n",
    "#### **Когда Accuracy полезна, а когда нет?**  \n",
    "**Хорошо работает**, когда классы сбалансированы (примеров каждого класса примерно поровну).  \n",
    "\n",
    "**Может вводить в заблуждение**, если классы несбалансированы.  \n",
    "*Пример:* Если 95% пациентов здоровы, а модель всегда предсказывает \"здоров\", то Accuracy = 95%, но модель бесполезна для выявления больных.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c66acae1-d783-426c-add2-95cb84c49695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "n = 6309\n",
    "distribution = model.predict(test_images[n:n+1,:,:,:])\n",
    "plt.imshow(np.array(test_images[n,:,:,:]))\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()\n",
    "print(np.argmax(distribution))\n",
    "print(test_labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e5f49-1572-4f92-8e9a-91244c63e092",
   "metadata": {},
   "source": [
    "## Как работает `Conv2D` в свёрточных нейронных сетях (CNN)?\n",
    "\n",
    "`Conv2D` — это **свёрточный слой** в нейронных сетях, предназначенный для обработки **двумерных данных** (например, изображений). Он применяет **фильтры (ядра)** к входному тензору, чтобы извлекать локальные признаки (например, края, текстуры, формы).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Основные параметры `Conv2D`**\n",
    "В TensorFlow/Keras слой `Conv2D` настраивается так:\n",
    "```python\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters=32,           # Количество фильтров\n",
    "    kernel_size=(3, 3),   # Размер ядра (высота, ширина)\n",
    "    strides=(1, 1),       # Шаг свёртки (по умолчанию 1)\n",
    "    padding='valid',      # 'valid' (без дополнения) или 'same' (с дополнением)\n",
    "    activation='relu',    # Функция активации (ReLU, sigmoid и др.)\n",
    "    input_shape=(28,28,1) # Формат входных данных (только для первого слоя)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Как происходит свёртка?**\n",
    "- **Входные данные**: Изображение в виде тензора формы `(height, width, channels)`.  \n",
    "  Например, `(32, 32, 3)` — изображение 32×32 пикселя с 3 каналами (RGB).  \n",
    "- **Фильтр (ядро)**: Матрица весов размера `(kernel_size[0], kernel_size[1], input_channels, filters)`.  \n",
    "  Например, для `kernel_size=(3,3)` и `filters=32` → ядро `(3, 3, 3, 32)` (если входные данные имеют 3 канала).  \n",
    "\n",
    "### Процесс свёртки:\n",
    "1. Фильтр \"скользит\" по изображению с шагом `strides`.  \n",
    "2. В каждой позиции вычисляется **поэлементное произведение** между частью изображения и ядром, затем результаты суммируются.  \n",
    "3. К сумме добавляется **смещение (bias)** и применяется **функция активации** (например, ReLU).  \n",
    "\n",
    "#### Пример (упрощённый):\n",
    "- **Вход**: Изображение 5×5, 1 канал.  \n",
    "- **Фильтр**: 3×3, 1 канал.  \n",
    "- **Результат**: Карта признаков 3×3 (если `padding='valid'`).  \n",
    "\n",
    "![animation](./lecture8/conv_animation.gif)\n",
    "---\n",
    "\n",
    "## 3. **Размер выходного тензора**\n",
    "Формула для вычисления размера выхода:\n",
    "$$\n",
    "\\text{output\\_size} = \\left\\lfloor \\frac{\\text{input\\_size} - \\text{kernel\\_size} + 2 \\cdot \\text{padding}}{\\text{strides}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "- **Если `padding='valid'`**:  \n",
    "  - Нет дополнения нулями.  \n",
    "  - Выход меньше входа.  \n",
    "  Пример: Вход `(32, 32)`, ядро `(3,3)` → выход `(30, 30)`.  \n",
    "\n",
    "- **Если `padding='same'`**:  \n",
    "  - Вход дополняется нулями, чтобы выход был того же размера, что и вход.  \n",
    "  Пример: Вход `(32, 32)`, ядро `(3,3)` → выход `(32, 32)`.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Пример с вычислениями**\n",
    "**Дано**:  \n",
    "- Вход: `(5, 5, 1)` (например, чёрно-белое изображение 5×5).  \n",
    "- Фильтр: 1 ядро `(3, 3, 1)` с весами:  \n",
    "  $$\n",
    "  \\begin{bmatrix}\n",
    "  1 & 0 & 1 \\\\\n",
    "  0 & 1 & 0 \\\\\n",
    "  1 & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "- `strides=(1,1)`, `padding='valid'`, активация `ReLU`.  \n",
    "\n",
    "**Результат свёртки**:  \n",
    "1. Фильтр применяется к каждому 3×3 участку изображения.  \n",
    "2. Для участка:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   1 & 2 & 3 \\\\\n",
    "   4 & 5 & 6 \\\\\n",
    "   7 & 8 & 9 \\\\\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "   вычисляется:  \n",
    "   $$\n",
    "   1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot 1 + 4 \\cdot 0 + 5 \\cdot 1 + 6 \\cdot 0 + 7 \\cdot 1 + 8 \\cdot 0 + 9 \\cdot 1 = 1 + 3 + 5 + 7 + 9 = 25\n",
    "   $$\n",
    "3. После `ReLU`: `max(0, 25) = 25`.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Визуализация в TensorFlow**\n",
    "Пример кода для проверки вывода `Conv2D`:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Создаём искусственное изображение 5x5x1\n",
    "input_image = np.array([[\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20],\n",
    "    [21, 22, 23, 24, 25]\n",
    "]], dtype=np.float32).reshape(1, 5, 5, 1)  # batch=1, height=5, width=5, channels=1\n",
    "\n",
    "# Создаём слой Conv2D с 1 фильтром 3x3\n",
    "conv_layer = tf.keras.layers.Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    kernel_initializer=tf.keras.initializers.Constant([[1, 0, 1], [0, 1, 0], [1, 0, 1]]),\n",
    "    bias_initializer='zeros',\n",
    "    activation='relu'\n",
    ")\n",
    "\n",
    "# Применяем свёртку\n",
    "output = conv_layer(input_image)\n",
    "print(output.numpy().squeeze())  # Убираем batch и channel\n",
    "```\n",
    "**Вывод**:\n",
    "```\n",
    "[[25. 28. 31.]\n",
    " [40. 43. 46.]\n",
    " [55. 58. 61.]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Зачем нужны несколько фильтров?**\n",
    "- Каждый фильтр `Conv2D` обучается выделять **разные признаки**.  \n",
    "  Например:  \n",
    "  - Первый фильтр может реагировать на вертикальные края.  \n",
    "  - Второй — на горизонтальные.  \n",
    "  - Третий — на диагональные текстуры.  \n",
    "- Чем глубже слой, тем более сложные признаки обнаруживаются (например, глаза, уши в CNN для распознавания лиц).\n",
    "\n",
    "---\n",
    "\n",
    "## Итог\n",
    "- `Conv2D` **автоматически обучает фильтры** для выделения признаков.  \n",
    "- **Параметры**:  \n",
    "  - `filters` — количество ядер,  \n",
    "  - `kernel_size` — размер ядра,  \n",
    "  - `strides` и `padding` — контроль размера выхода.  \n",
    "- **Результат**: 3D-тензор `(new_height, new_width, filters)`.  \n",
    "\n",
    "Пример из реального мира: В первом слое CNN для CIFAR-10 `Conv2D(32, (3,3))` создаёт 32 карты признаков 30×30 (если вход 32×32 с `padding='valid'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f0041-5476-43ab-8a95-f92366223c62",
   "metadata": {},
   "source": [
    "### **Как работает `MaxPooling2D` в свёрточных нейронных сетях (CNN)?**\n",
    "\n",
    "`MaxPooling2D` — это **пулинговый слой** (подвыборка), который уменьшает размерность карт признаков, сохраняя наиболее важную информацию. Он **не обучается** (не имеет весов), а просто применяет операцию максимума к локальным областям входного тензора.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Основные параметры `MaxPooling2D`**\n",
    "В TensorFlow/Keras слой настраивается так:\n",
    "```python\n",
    "tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),  # Размер окна пулинга (высота × ширина)\n",
    "    strides=None,      # Шаг пулинга (по умолчанию = pool_size)\n",
    "    padding='valid',   # 'valid' (без дополнения) или 'same' (с дополнением)\n",
    ")\n",
    "```\n",
    "- **`pool_size`**: Размер области, из которой берётся максимум (обычно `(2, 2)` или `(3, 3)`).  \n",
    "- **`strides`**: Шаг, с которым окно пулинга перемещается по данным. По умолчанию равен `pool_size`.  \n",
    "- **`padding`**:  \n",
    "  - `'valid'` — без дополнения нулями (выход меньше входа),  \n",
    "  - `'same'` — с дополнением (выход того же размера, что и вход).  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. Как работает `MaxPooling2D`?**\n",
    "- **Вход**: 3D-тензор формы `(height, width, channels)`.  \n",
    "- **Операция**:  \n",
    "  1. Окно размера `pool_size` скользит по входному тензору с шагом `strides`.  \n",
    "  2. В каждой позиции выбирается **максимальное значение** из этой области.  \n",
    "  3. Канал обрабатывается независимо (пулинг применяется к каждому каналу отдельно).  \n",
    "\n",
    "### **Пример (числовой)**\n",
    "**Дано**:  \n",
    "- Входная матрица (1 канал, для простоты):\n",
    "  \\[\n",
    "  \\begin{bmatrix}\n",
    "  1 & 2 & 3 & 4 \\\\\n",
    "  5 & 6 & 7 & 8 \\\\\n",
    "  9 & 10 & 11 & 12 \\\\\n",
    "  13 & 14 & 15 & 16 \\\\\n",
    "  \\end{bmatrix}\n",
    "  \\]\n",
    "- `pool_size=(2, 2)`, `strides=(2, 2)`, `padding='valid'`.\n",
    "\n",
    "**Шаги**:  \n",
    "1. Применяем окно 2×2 к левому верхнему углу:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   1 & 2 \\\\\n",
    "   5 & 6 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(1, 2, 5, 6) = 6\n",
    "   $$\n",
    "2. Сдвигаем окно на `strides=2` вправо:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   3 & 4 \\\\\n",
    "   7 & 8 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(3, 4, 7, 8) = 8\n",
    "   $$\n",
    "3. Аналогично для нижних строк:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   9 & 10 \\\\\n",
    "   13 & 14 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(9, 10, 13, 14) = 14\n",
    "   $$\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   11 & 12 \\\\\n",
    "   15 & 16 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(11, 12, 15, 16) = 16\n",
    "   $$\n",
    "\n",
    "**Итоговый выход**:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "6 & 8 \\\\\n",
    "14 & 16 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "*(Размер уменьшился с 4×4 до 2×2.)*\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Визуализация**\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\" width=\"400\" alt=\"MaxPooling2D Example\">\n",
    "</div>\n",
    "\n",
    "*(Пример `MaxPooling2D` с `pool_size=(2,2)` и `strides=2`. Источник: Computer Science Wiki)*\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Размер выходного тензора**\n",
    "Формула для вычисления размера выхода:\n",
    "$$\n",
    "\\text{output\\_size} = \\left\\lfloor \\frac{\\text{input\\_size} - \\text{pool\\_size}}{\\text{strides}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "- Если `padding='same'`, TensorFlow автоматически дополняет вход нулями, чтобы выход был такого же размера, как вход.  \n",
    "- Пример:  \n",
    "  - Вход `(30, 30, 64)`, `pool_size=(2,2)`, `strides=2` → выход `(15, 15, 64)`.  \n",
    "  - Вход `(31, 31, 64)`, `pool_size=(2,2)`, `strides=2` → выход `(15, 15, 64)` (так как `⌊(31-2)/2⌋ + 1 = 15`).  \n",
    "\n",
    "---\n",
    "\n",
    "## **5. Пример кода в TensorFlow**\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Создаём искусственный тензор (1 изображение 4x4 с 1 каналом)\n",
    "input_tensor = np.array([[\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "]], dtype=np.float32).reshape(1, 4, 4, 1)  # (batch=1, height=4, width=4, channels=1)\n",
    "\n",
    "# Создаём слой MaxPooling2D\n",
    "max_pool = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2),\n",
    "    padding='valid'\n",
    ")\n",
    "\n",
    "# Применяем пулинг\n",
    "output = max_pool(input_tensor)\n",
    "print(output.numpy().squeeze())  # Убираем batch и channel\n",
    "```\n",
    "**Вывод**:\n",
    "```\n",
    "[[ 6.  8.]\n",
    " [14. 16.]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Зачем нужен `MaxPooling2D`?**\n",
    "1. **Уменьшение размерности**:  \n",
    "   - Сокращает объём вычислений в сети.  \n",
    "   - Уменьшает риск переобучения.  \n",
    "2. **Инвариантность к малым сдвигам**:  \n",
    "   - Максимальный элемент в области останется тем же, даже если объект немного сместился.  \n",
    "3. **Акцентирование важных признаков**:  \n",
    "   - Сохраняет только самые сильные активации (например, края, текстуры).  \n",
    "\n",
    "---\n",
    "\n",
    "## **7. Чем отличается от `AveragePooling2D`?**\n",
    "| **`MaxPooling2D`**         | **`AveragePooling2D`**       |\n",
    "|----------------------------|------------------------------|\n",
    "| Берёт максимум из области  | Берёт среднее из области     |\n",
    "| Подходит для выделения четких признаков (например, краёв) | Лучше для сглаживания (например, в классических CNN) |\n",
    "\n",
    "---\n",
    "\n",
    "## **Итог**\n",
    "- `MaxPooling2D` **уменьшает размерность** данных, выбирая **максимальные значения** в локальных областях.  \n",
    "- Основные параметры:  \n",
    "  - `pool_size` — размер окна (обычно `(2, 2)`),  \n",
    "  - `strides` — шаг (обычно равен `pool_size`),  \n",
    "  - `padding` — контролирует размер выхода.  \n",
    "- Применяется после свёрточных слоёв для снижения вычислительной сложности.  \n",
    "\n",
    "Пример архитектуры CNN с `MaxPooling2D`:\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2))\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1329e-495e-42ef-861a-0911b22d315e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
