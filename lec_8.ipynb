{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5285ceb4-8dda-41ee-a873-52984de558ee",
   "metadata": {},
   "source": [
    "## Сверточные нейронные сети\n",
    "\n",
    "Идея создания сверточных нейронных сетей обсуждалась еще в середине XX века. Но к ней вернулись лишь в 2012 году. Тогда математики Алекс Крижевский и Джеффри Хинтон (Нобелевка по физике 2024) представили на международном конкурсе нейросеть AlexNet. По сравнению с аналогичными моделями она совершала почти на 50% меньше ошибок при распознавании изображений: их количество снизилось с 26 до 15%. Сейчас точность стала еще выше. Например, при распознавании лиц в толпе показатель составляет 99,8%\n",
    "\n",
    "![cnn](./lecture8/cnn.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e8e564-08ff-4bf9-a94c-fc736a147c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "# Загрузка данных CIFAR-10\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffbb0d-ba40-4d19-8761-d6212aba39b6",
   "metadata": {},
   "source": [
    "### Размеченные данные - 10 категорий\n",
    "\n",
    "![table](./lecture8/labels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7102faf1-0ee9-48c2-b01b-680f4733184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 1230\n",
    "plt.imshow(np.array(test_images[n,:,:,:]))\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()\n",
    "print(test_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2cac021-7b19-457a-b07a-1ab9c1de2f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.3245 - loss: 1.8152 - val_accuracy: 0.5405 - val_loss: 1.2900\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.5638 - loss: 1.2392 - val_accuracy: 0.6184 - val_loss: 1.0863\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - accuracy: 0.6290 - loss: 1.0591 - val_accuracy: 0.6413 - val_loss: 1.0254\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.6641 - loss: 0.9513 - val_accuracy: 0.6618 - val_loss: 0.9598\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.6918 - loss: 0.8751 - val_accuracy: 0.6592 - val_loss: 0.9760\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.7132 - loss: 0.8183 - val_accuracy: 0.6612 - val_loss: 0.9913\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.7321 - loss: 0.7640 - val_accuracy: 0.6907 - val_loss: 0.8853\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.7407 - loss: 0.7305 - val_accuracy: 0.7035 - val_loss: 0.8587\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.7599 - loss: 0.6799 - val_accuracy: 0.6991 - val_loss: 0.8930\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.7717 - loss: 0.6446 - val_accuracy: 0.6921 - val_loss: 0.9026\n",
      "313/313 - 3s - 10ms/step - accuracy: 0.6921 - loss: 0.9026\n",
      "Test accuracy: 0.6921\n"
     ]
    }
   ],
   "source": [
    "# Нормализация пикселей (0-255 -> 0-1)\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Создание модели CNN\n",
    "model = models.Sequential([\n",
    "    # Свёрточные слои + пулинг\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "\n",
    "    # Полносвязные слои\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)  # 10 классов для CIFAR-10\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")\n",
    "\n",
    "# Оценка\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3060a-e17c-4a8e-9790-082a92a00848",
   "metadata": {},
   "source": [
    "### **Формула вычисления Accuracy**  \n",
    "**Accuracy (точность)** — это одна из основных метрик для оценки качества классификационных моделей в машинном обучении. Она показывает долю правильно предсказанных объектов относительно общего количества предсказаний.  \n",
    "\n",
    "Accuracy вычисляется по формуле:  \n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Количество верных предсказаний}}{\\text{Общее количество предсказаний}} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$  \n",
    "\n",
    "Где:  \n",
    "- **TP (True Positives)** — количество верно предсказанных положительных примеров.  \n",
    "- **TN (True Negatives)** — количество верно предсказанных отрицательных примеров.  \n",
    "- **FP (False Positives)** — количество отрицательных примеров, ошибочно предсказанных как положительные.  \n",
    "- **FN (False Negatives)** — количество положительных примеров, ошибочно предсказанных как отрицательные.\n",
    "\n",
    "\n",
    "#### **Когда Accuracy полезна, а когда нет?**  \n",
    "**Хорошо работает**, когда классы сбалансированы (примеров каждого класса примерно поровну).  \n",
    "\n",
    "**Может вводить в заблуждение**, если классы несбалансированы.  \n",
    "*Пример:* Если 95% пациентов здоровы, а модель всегда предсказывает \"здоров\", то Accuracy = 95%, но модель бесполезна для выявления больных.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c66acae1-d783-426c-add2-95cb84c49695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "distribution = model.predict(test_images[n:n+1,:,:,:])\n",
    "plt.imshow(np.array(test_images[n,:,:,:]))\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()\n",
    "print(np.argmax(distribution))\n",
    "print(test_labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e5f49-1572-4f92-8e9a-91244c63e092",
   "metadata": {},
   "source": [
    "## Как работает `Conv2D` в свёрточных нейронных сетях (CNN)?\n",
    "\n",
    "`Conv2D` — это **свёрточный слой** в нейронных сетях, предназначенный для обработки **двумерных данных** (например, изображений). Он применяет **фильтры (ядра)** к входному тензору, чтобы извлекать локальные признаки (например, края, текстуры, формы).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Основные параметры `Conv2D`**\n",
    "В TensorFlow/Keras слой `Conv2D` настраивается так:\n",
    "```python\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters=32,           # Количество фильтров\n",
    "    kernel_size=(3, 3),   # Размер ядра (высота, ширина)\n",
    "    strides=(1, 1),       # Шаг свёртки (по умолчанию 1)\n",
    "    padding='valid',      # 'valid' (без дополнения) или 'same' (с дополнением)\n",
    "    activation='relu',    # Функция активации (ReLU, sigmoid и др.)\n",
    "    input_shape=(28,28,1) # Формат входных данных (только для первого слоя)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Как происходит свёртка?**\n",
    "- **Входные данные**: Изображение в виде тензора формы `(height, width, channels)`.  \n",
    "  Например, `(32, 32, 3)` — изображение 32×32 пикселя с 3 каналами (RGB).  \n",
    "- **Фильтр (ядро)**: Матрица весов размера `(kernel_size[0], kernel_size[1], input_channels, filters)`.  \n",
    "  Например, для `kernel_size=(3,3)` и `filters=32` → ядро `(3, 3, 3, 32)` (если входные данные имеют 3 канала).  \n",
    "\n",
    "### Процесс свёртки:\n",
    "1. Фильтр \"скользит\" по изображению с шагом `strides`.  \n",
    "2. В каждой позиции вычисляется **поэлементное произведение** между частью изображения и ядром, затем результаты суммируются.  \n",
    "3. К сумме добавляется **смещение (bias)** и применяется **функция активации** (например, ReLU).  \n",
    "\n",
    "#### Пример (упрощённый):\n",
    "- **Вход**: Изображение 5×5, 1 канал.  \n",
    "- **Фильтр**: 3×3, 1 канал.  \n",
    "- **Результат**: Карта признаков 3×3 (если `padding='valid'`).  \n",
    "\n",
    "![animation](./lecture8/conv_animation.gif)\n",
    "---\n",
    "\n",
    "## 3. **Размер выходного тензора**\n",
    "Формула для вычисления размера выхода:\n",
    "$$\n",
    "\\text{output\\_size} = \\left\\lfloor \\frac{\\text{input\\_size} - \\text{kernel\\_size} + 2 \\cdot \\text{padding}}{\\text{strides}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "- **Если `padding='valid'`**:  \n",
    "  - Нет дополнения нулями.  \n",
    "  - Выход меньше входа.  \n",
    "  Пример: Вход `(32, 32)`, ядро `(3,3)` → выход `(30, 30)`.  \n",
    "\n",
    "- **Если `padding='same'`**:  \n",
    "  - Вход дополняется нулями, чтобы выход был того же размера, что и вход.  \n",
    "  Пример: Вход `(32, 32)`, ядро `(3,3)` → выход `(32, 32)`.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Пример с вычислениями**\n",
    "**Дано**:  \n",
    "- Вход: `(5, 5, 1)` (например, чёрно-белое изображение 5×5).  \n",
    "- Фильтр: 1 ядро `(3, 3, 1)` с весами:  \n",
    "  $$\n",
    "  \\begin{bmatrix}\n",
    "  1 & 0 & 1 \\\\\n",
    "  0 & 1 & 0 \\\\\n",
    "  1 & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "- `strides=(1,1)`, `padding='valid'`, активация `ReLU`.  \n",
    "\n",
    "**Результат свёртки**:  \n",
    "1. Фильтр применяется к каждому 3×3 участку изображения.  \n",
    "2. Для участка:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   1 & 2 & 3 \\\\\n",
    "   4 & 5 & 6 \\\\\n",
    "   7 & 8 & 9 \\\\\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "   вычисляется:  \n",
    "   $$\n",
    "   1 \\cdot 1 + 2 \\cdot 0 + 3 \\cdot 1 + 4 \\cdot 0 + 5 \\cdot 1 + 6 \\cdot 0 + 7 \\cdot 1 + 8 \\cdot 0 + 9 \\cdot 1 = 1 + 3 + 5 + 7 + 9 = 25\n",
    "   $$\n",
    "3. После `ReLU`: `max(0, 25) = 25`.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Визуализация в TensorFlow**\n",
    "Пример кода для проверки вывода `Conv2D`:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Создаём искусственное изображение 5x5x1\n",
    "input_image = np.array([[\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20],\n",
    "    [21, 22, 23, 24, 25]\n",
    "]], dtype=np.float32).reshape(1, 5, 5, 1)  # batch=1, height=5, width=5, channels=1\n",
    "\n",
    "# Создаём слой Conv2D с 1 фильтром 3x3\n",
    "conv_layer = tf.keras.layers.Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    kernel_initializer=tf.keras.initializers.Constant([[1, 0, 1], [0, 1, 0], [1, 0, 1]]),\n",
    "    bias_initializer='zeros',\n",
    "    activation='relu'\n",
    ")\n",
    "\n",
    "# Применяем свёртку\n",
    "output = conv_layer(input_image)\n",
    "print(output.numpy().squeeze())  # Убираем batch и channel\n",
    "```\n",
    "**Вывод**:\n",
    "```\n",
    "[[25. 28. 31.]\n",
    " [40. 43. 46.]\n",
    " [55. 58. 61.]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Зачем нужны несколько фильтров?**\n",
    "- Каждый фильтр `Conv2D` обучается выделять **разные признаки**.  \n",
    "  Например:  \n",
    "  - Первый фильтр может реагировать на вертикальные края.  \n",
    "  - Второй — на горизонтальные.  \n",
    "  - Третий — на диагональные текстуры.  \n",
    "- Чем глубже слой, тем более сложные признаки обнаруживаются (например, глаза, уши в CNN для распознавания лиц).\n",
    "\n",
    "---\n",
    "\n",
    "## Итог\n",
    "- `Conv2D` **автоматически обучает фильтры** для выделения признаков.  \n",
    "- **Параметры**:  \n",
    "  - `filters` — количество ядер,  \n",
    "  - `kernel_size` — размер ядра,  \n",
    "  - `strides` и `padding` — контроль размера выхода.  \n",
    "- **Результат**: 3D-тензор `(new_height, new_width, filters)`.  \n",
    "\n",
    "Пример из реального мира: В первом слое CNN для CIFAR-10 `Conv2D(32, (3,3))` создаёт 32 карты признаков 30×30 (если вход 32×32 с `padding='valid'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f0041-5476-43ab-8a95-f92366223c62",
   "metadata": {},
   "source": [
    "### **Как работает `MaxPooling2D` в свёрточных нейронных сетях (CNN)?**\n",
    "\n",
    "`MaxPooling2D` — это **пулинговый слой** (подвыборка), который уменьшает размерность карт признаков, сохраняя наиболее важную информацию. Он **не обучается** (не имеет весов), а просто применяет операцию максимума к локальным областям входного тензора.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Основные параметры `MaxPooling2D`**\n",
    "В TensorFlow/Keras слой настраивается так:\n",
    "```python\n",
    "tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),  # Размер окна пулинга (высота × ширина)\n",
    "    strides=None,      # Шаг пулинга (по умолчанию = pool_size)\n",
    "    padding='valid',   # 'valid' (без дополнения) или 'same' (с дополнением)\n",
    ")\n",
    "```\n",
    "- **`pool_size`**: Размер области, из которой берётся максимум (обычно `(2, 2)` или `(3, 3)`).  \n",
    "- **`strides`**: Шаг, с которым окно пулинга перемещается по данным. По умолчанию равен `pool_size`.  \n",
    "- **`padding`**:  \n",
    "  - `'valid'` — без дополнения нулями (выход меньше входа),  \n",
    "  - `'same'` — с дополнением (выход того же размера, что и вход).  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. Как работает `MaxPooling2D`?**\n",
    "- **Вход**: 3D-тензор формы `(height, width, channels)`.  \n",
    "- **Операция**:  \n",
    "  1. Окно размера `pool_size` скользит по входному тензору с шагом `strides`.  \n",
    "  2. В каждой позиции выбирается **максимальное значение** из этой области.  \n",
    "  3. Канал обрабатывается независимо (пулинг применяется к каждому каналу отдельно).  \n",
    "\n",
    "### **Пример (числовой)**\n",
    "**Дано**:  \n",
    "- Входная матрица (1 канал, для простоты):\n",
    "  \\[\n",
    "  \\begin{bmatrix}\n",
    "  1 & 2 & 3 & 4 \\\\\n",
    "  5 & 6 & 7 & 8 \\\\\n",
    "  9 & 10 & 11 & 12 \\\\\n",
    "  13 & 14 & 15 & 16 \\\\\n",
    "  \\end{bmatrix}\n",
    "  \\]\n",
    "- `pool_size=(2, 2)`, `strides=(2, 2)`, `padding='valid'`.\n",
    "\n",
    "**Шаги**:  \n",
    "1. Применяем окно 2×2 к левому верхнему углу:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   1 & 2 \\\\\n",
    "   5 & 6 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(1, 2, 5, 6) = 6\n",
    "   $$\n",
    "2. Сдвигаем окно на `strides=2` вправо:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   3 & 4 \\\\\n",
    "   7 & 8 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(3, 4, 7, 8) = 8\n",
    "   $$\n",
    "3. Аналогично для нижних строк:\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   9 & 10 \\\\\n",
    "   13 & 14 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(9, 10, 13, 14) = 14\n",
    "   $$\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   11 & 12 \\\\\n",
    "   15 & 16 \\\\\n",
    "   \\end{bmatrix} \\rightarrow \\max(11, 12, 15, 16) = 16\n",
    "   $$\n",
    "\n",
    "**Итоговый выход**:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "6 & 8 \\\\\n",
    "14 & 16 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "*(Размер уменьшился с 4×4 до 2×2.)*\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Визуализация**\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\" width=\"400\" alt=\"MaxPooling2D Example\">\n",
    "</div>\n",
    "\n",
    "*(Пример `MaxPooling2D` с `pool_size=(2,2)` и `strides=2`. Источник: Computer Science Wiki)*\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Размер выходного тензора**\n",
    "Формула для вычисления размера выхода:\n",
    "$$\n",
    "\\text{output\\_size} = \\left\\lfloor \\frac{\\text{input\\_size} - \\text{pool\\_size}}{\\text{strides}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "- Если `padding='same'`, TensorFlow автоматически дополняет вход нулями, чтобы выход был такого же размера, как вход.  \n",
    "- Пример:  \n",
    "  - Вход `(30, 30, 64)`, `pool_size=(2,2)`, `strides=2` → выход `(15, 15, 64)`.  \n",
    "  - Вход `(31, 31, 64)`, `pool_size=(2,2)`, `strides=2` → выход `(15, 15, 64)` (так как `⌊(31-2)/2⌋ + 1 = 15`).  \n",
    "\n",
    "---\n",
    "\n",
    "## **5. Пример кода в TensorFlow**\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Создаём искусственный тензор (1 изображение 4x4 с 1 каналом)\n",
    "input_tensor = np.array([[\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "]], dtype=np.float32).reshape(1, 4, 4, 1)  # (batch=1, height=4, width=4, channels=1)\n",
    "\n",
    "# Создаём слой MaxPooling2D\n",
    "max_pool = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2),\n",
    "    padding='valid'\n",
    ")\n",
    "\n",
    "# Применяем пулинг\n",
    "output = max_pool(input_tensor)\n",
    "print(output.numpy().squeeze())  # Убираем batch и channel\n",
    "```\n",
    "**Вывод**:\n",
    "```\n",
    "[[ 6.  8.]\n",
    " [14. 16.]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Зачем нужен `MaxPooling2D`?**\n",
    "1. **Уменьшение размерности**:  \n",
    "   - Сокращает объём вычислений в сети.  \n",
    "   - Уменьшает риск переобучения.  \n",
    "2. **Инвариантность к малым сдвигам**:  \n",
    "   - Максимальный элемент в области останется тем же, даже если объект немного сместился.  \n",
    "3. **Акцентирование важных признаков**:  \n",
    "   - Сохраняет только самые сильные активации (например, края, текстуры).  \n",
    "\n",
    "---\n",
    "\n",
    "## **7. Чем отличается от `AveragePooling2D`?**\n",
    "| **`MaxPooling2D`**         | **`AveragePooling2D`**       |\n",
    "|----------------------------|------------------------------|\n",
    "| Берёт максимум из области  | Берёт среднее из области     |\n",
    "| Подходит для выделения четких признаков (например, краёв) | Лучше для сглаживания (например, в классических CNN) |\n",
    "\n",
    "---\n",
    "\n",
    "## **Итог**\n",
    "- `MaxPooling2D` **уменьшает размерность** данных, выбирая **максимальные значения** в локальных областях.  \n",
    "- Основные параметры:  \n",
    "  - `pool_size` — размер окна (обычно `(2, 2)`),  \n",
    "  - `strides` — шаг (обычно равен `pool_size`),  \n",
    "  - `padding` — контролирует размер выхода.  \n",
    "- Применяется после свёрточных слоёв для снижения вычислительной сложности.  \n",
    "\n",
    "Пример архитектуры CNN с `MaxPooling2D`:\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2))\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1329e-495e-42ef-861a-0911b22d315e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
